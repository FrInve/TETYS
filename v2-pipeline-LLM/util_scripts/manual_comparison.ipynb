{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/conda/envs/jelena/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/data/conda/envs/jelena/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/data/conda/envs/jelena/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/data/conda/envs/jelena/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ['HF_HOME'] = '/data/hf_cache'\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import datetime as dt\n",
    "from time import sleep\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from bertopic import BERTopic\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP = 1\n",
    "CONFIG = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = BERTopic.load(f\"../models/group_{GROUP}/model_group_1_dbcv_0_44\", embedding_model=\"sentence-transformers/allenai-specter\")\n",
    "model_2 = BERTopic.load(f\"../models/group_{GROUP}/random_LLM_model_group_1_dbcv_0_52\", embedding_model=\"Salesforce/SFR-Embedding-2_R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_model_1 = model_1.get_topic_info()\n",
    "topics_model_2 = model_2.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_model_1 = [model_1.get_topic(topic)[0:10] for topic in topics_model_1.Topic]\n",
    "keywords_model_2 = [model_2.get_topic(topic)[0:10] for topic in topics_model_2.Topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_1_strings = [' '.join([kw[0] for kw in keywords]) for keywords in keywords_model_1]\n",
    "topics_2_strings = [' '.join([kw[0] for kw in keywords]) for keywords in keywords_model_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer().fit(topics_1_strings + topics_2_strings)\n",
    "topic_1_vectors = vectorizer.transform(topics_1_strings)\n",
    "topic_2_vectors = vectorizer.transform(topics_2_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = cosine_similarity(topic_1_vectors, topic_2_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_macth_similarity_threshold = 0.2\n",
    "model_1_non_matches = similarity_matrix.max(axis=1) <= non_macth_similarity_threshold\n",
    "model_1_non_found_count = model_1_non_matches.sum()\n",
    "model_2_non_matches = similarity_matrix.max(axis=0) <= non_macth_similarity_threshold\n",
    "model_2_non_found_count = model_2_non_matches.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "macth_similarity_threshold = 0.4\n",
    "model_1_matches = similarity_matrix.max(axis=1) >= macth_similarity_threshold\n",
    "model_1_found_count = model_1_matches.sum()\n",
    "model_2_matches = similarity_matrix.max(axis=0) >= macth_similarity_threshold\n",
    "model_2_found_count = model_2_matches.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Topics from Model 1 not found in Model 2: {model_1_non_found_count} / {len(keywords_model_1)}\")\n",
    "print(f\"Topics from Model 2 not found in Model 1: {model_2_non_found_count} / {len(keywords_model_2)}\")\n",
    "model_1_non_found_percentage = (model_1_non_found_count / len(keywords_model_1)) * 100\n",
    "model_2_non_found_percentage = (model_2_non_found_count / len(keywords_model_2)) * 100\n",
    "\n",
    "print(f\"Topics from Model 1 not found in Model 2: {model_1_non_found_count} / {len(keywords_model_1)} \"\n",
    "      f\"({model_1_non_found_percentage:.2f}%)\")\n",
    "\n",
    "print(f\"Topics from Model 2 not found in Model 1: {model_2_non_found_count} / {len(keywords_model_2)} \"\n",
    "      f\"({model_2_non_found_percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Topics from Model 1 found in Model 2: {model_1_found_count} / {len(keywords_model_1)}\")\n",
    "print(f\"Topics from Model 2 found in Model 1: {model_2_found_count} / {len(keywords_model_2)}\")\n",
    "model_1_found_percentage = (model_1_found_count / len(keywords_model_1)) * 100\n",
    "model_2_found_percentage = (model_2_found_count / len(keywords_model_2)) * 100\n",
    "\n",
    "print(f\"Topics from Model 1 found in Model 2: {model_1_found_count} / {len(keywords_model_1)} \"\n",
    "      f\"({model_1_found_percentage:.2f}%)\")\n",
    "\n",
    "print(f\"Topics from Model 2 found in Model 1: {model_2_found_count} / {len(keywords_model_2)} \"\n",
    "      f\"({model_2_found_percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matched_topics_df_model_1 = pd.DataFrame({\n",
    "#     'Model 1 Topic': np.where(model_1_matches)[0],\n",
    "#     'Model 1 Keywords': [topics_1_strings[i] for i in np.where(model_1_matches)[0]],\n",
    "#     'Model 2 Topic': similarity_matrix.argmax(axis=1)[model_1_matches],\n",
    "#     'Model 2 Keywords': [topics_2_strings[i] for i in similarity_matrix.argmax(axis=1)[model_1_matches]],\n",
    "#     'Cosine Similarity': similarity_matrix.max(axis=1)[model_1_matches]\n",
    "# })\n",
    "\n",
    "# matched_topics_df_model_2 = pd.DataFrame({\n",
    "#     'Model 2 Topic': np.where(model_2_matches)[0],\n",
    "#     'Model 2 Keywords': [topics_2_strings[i] for i in np.where(model_2_matches)[0]],\n",
    "#     'Model 1 Topic': similarity_matrix.argmax(axis=0)[model_2_matches],\n",
    "#     'Model 1 Keywords': [topics_1_strings[i] for i in similarity_matrix.argmax(axis=0)[model_2_matches]],\n",
    "#     'Cosine Similarity': similarity_matrix.max(axis=0)[model_2_matches]\n",
    "# })\n",
    "\n",
    "# print(\"\\nMatched Topics between Model 1 and Model 2:\")\n",
    "# print(matched_topics_df_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matched_topics_df_model_2.to_csv('macthing_topics_model_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jelena",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
